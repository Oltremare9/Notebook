# 多线程

### <u>线程同步的方式</u>

#### object的wait notify 

> 需要阻塞
>
> JVM会为一个使用内部锁（synchronized）的对象维护两个集合，**Entry Set**和**Wait Set**
>
> 对于Entry Set：如果线程A已经持有了对象锁，此时如果有其他线程也想获得该对象锁的话，它只能进入Entry Set，并且处于线程的BLOCKED状态。
>
> 对于Wait Set：如果线程A调用了wait()方法，那么线程A会释放该对象的锁，进入到Wait Set，并且处于线程的WAITING状态。
>
> 某个线程B想要获得对象锁，一般情况下有两个先决条件，一是对象锁已经被释放了（如曾经持有锁的前任线程A执行完了synchronized代码块或者调用了wait()方法等等），二是线程B已处于RUNNABLE状态。
>
> 对于Entry Set中的线程，当对象锁被释放的时候，JVM会唤醒处于Entry Set中的某一个线程，这个线程的状态就从BLOCKED转变为RUNNABLE。
>
> 对于Wait Set中的线程，当对象的notify()方法被调用时，JVM会唤醒处于Wait Set中的某一个线程，这个线程的状态就从WAITING转变为RUNNABLE；或者当notifyAll()方法被调用时，Wait Set中的全部线程会转变为RUNNABLE状态。所有Wait Set中被唤醒的线程会被转移到Entry Set中。

```java
	static class A extends Thread {
        public void run() {
            while (true) {
                synchronized (lockA){
                    System.out.print("A");
                    lockA.notify();
                    try {
                        lockA.wait();
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                }
            }
        }
    }
```

> 此处交替输出AB所以使用一个锁来限制



#### 简单的显式lock的方式 和信号量方式类似

```java
	static Lock lock = new ReentrantLock();
    static Integer i = new Integer(3);

    static class A extends Thread {
        public void run() {
            while (true) {
                lock.lock();
                while (i % 3 == 0) {
                    System.out.print("a");
                    i++;
                }
                lock.unlock();
            }
        }
    }
```



#### condition的await和signal

```java
	static Lock lock = new ReentrantLock();
    static Condition a=lock.newCondition();
    static Condition b=lock.newCondition();
    static Condition c=lock.newCondition();
```

> 通过lock来创建不同的condition 每个condition类似于对应某个输出
>
> await对应wait  signal对应notify signalAll对应notifyAll

```java
	static class A extends Thread {
        public void run() {
            while (true) {
                lock.lock();
                while (i % 3 != 0) {
                    try {
                        a.await();
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                }
                i++;
                System.out.print("a");
                b.signal();
                lock.unlock();
            }
        }
    }
```

##### condition原理 

*（AQS维护blocked condition维护一个waiting的FIFO队列）*

> 我们知道Lock的本质是AQS，AQS自己维护的队列是当前等待资源的队列，AQS会在资源被释放后，依次唤醒队列中从前到后的所有节点，使他们对应的线程恢复执行，直到队列为空。而Condition自己也维护了一个队列，该队列的作用是维护一个等待signal信号的队列。但是，两个队列的作用不同的，事实上，每个线程也仅仅会同时存在以上两个队列中的一个，流程是这样的：
>
> \1. 线程1调用reentrantLock.lock时，尝试获取锁。如果成功，则返回，从AQS的队列中移除线程；否则阻塞，保持在AQS的等待队列中。
> \2. 线程1调用await方法被调用时，对应操作是被加入到Condition的等待队列中，等待signal信号；同时释放锁。
> \3. 锁被释放后，会唤醒AQS队列中的头结点，所以线程2会获取到锁。
> \4. 线程2调用signal方法，这个时候Condition的等待队列中只有线程1一个节点，于是它被取出来，并被加入到AQS的等待队列中。注意，这个时候，线程1 并没有被唤醒，只是被加入AQS等待队列。
> \5. signal方法执行完毕，线程2调用unLock()方法，释放锁。这个时候因为AQS中只有线程1，于是，线程1被唤醒，线程1恢复执行。
> 所以：
> 发送signal信号只是将Condition队列中的线程加到AQS的等待队列中。只有到发送signal信号的线程调用reentrantLock.unlock()释放锁后，这些线程才会被唤醒。
>
> 可以看到，整个协作过程是靠结点在AQS的等待队列和Condition的等待队列中来回移动实现的，Condition作为一个条件类，很好的自己维护了一个等待信号的队列，并在适时的时候将结点加入到AQS的等待队列中来实现的唤醒操作。

#### Semaphore信号量

> 类似于同步信号量的形式，更加方便操作

```java
	static Semaphore a=new Semaphore(1);
    static Semaphore b=new Semaphore(0);
    static class A extends Thread{
        public void run(){
            while(true) {
                try {
                    a.acquire();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.print("a");
                b.release();
            }
        }
    }
    static class B extends Thread{
        public void run(){
            while(true) {

                try {
                    sleep(100);
                    b.acquire();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println("b");
                a.release();
            }
        }
    }
    static class C extends Thread{
        public void run(){
            while(true) {
                try {
                    sleep(100);
                    b.acquire();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println("c");
                a.release();
            }
        }
    }
```

> 交替输出AB 或 AC





### <u>ThreadLocal软引用</u>

> **强引用**：只有当没有引用指向该对象才会进行gc
>
> **软引用**：只有在堆空间满后才会在gc时回收
>
> **软引用**：被gc时会就会被回收u
>
> ThreadLocal作为线程私有属性 thread中会有一个强引用指向threadlocal对象
>
> threadlocal的本质是thread本身维护一个map，其中键为弱引用的threadlocak 值为object
>
> 之所以使用软引用是防止在thread对象的强引用消除后，仍有key指针指向threadlocal导致空间无法回收
>
> 但是即使使用了弱引用后，仍有可能需要remove来消除这条记录

## 线程池

### <u>线程池的概念</u>

> #### 优势
>
> ​	降低系统资源消耗，通过重用已存在的线程，降低线程创建和销毁造成的消耗；
>
> ​	提高系统响应速度，当有任务到达时，通过复用已存在的线程，无需等待新线程的创建便能立即执行
>
> ​	方便线程并发数的管控。因为线程若是无限制的创建，可能会导致内存占用过多而产生OOM，并且会造成cpu过度切换
>
> ​	提供更强大的功能，延时定时线程池。

> #### 核心参数
>
> > ​	**corePoolSize核心线程池大小**
> >
> > ​	当向线程池提交一个任务时，若线程池已创建的线程数小于corePoolSize，即便此时存在空闲线程，也会通过创建一个新线程来执行该任务，直到已创建的线程数大于或等于corePoolSize时
>
> > ​	**maximumPoolSize线程池最大大小**
> >
> > ​	线程池所允许的最大线程个数。当队列满了，且已创建的线程数小于maximumPoolSize，则线程池会创建新的线程来执行任务。**无界队列此参数无效**
>
> > ​	**keepAliveTime线程存活保持时间**
> >
> > ​	当线程池中线程数大于核心线程数时，线程的空闲时间如果超过线程存活时间，那么这个线程就会被销毁，直到线程池中的线程数小于等于核心线程数。
>
> > ​	**workQueue任务队列**
> >
> > ​	用于传输和保存等待执行任务的阻塞队列
>
> > ​	**threadFactory线程工厂**
> >
> > ​	用于创建新线程。threadFactory创建的线程也是采用new Thread()方式
>
> > ​	**handler线程饱和策略**
> >
> > ​	当线程池和队列都满了，再加入线程会执行此策略

![](https://upload-images.jianshu.io/upload_images/6024478-88ee7b20f8f45825.png?imageMogr2/auto-orient/strip|imageView2/2/w/937/format/webp)

### <u>为什么使用阻塞队列</u>

> 1 使用队列可以限制线程无限制的创建，避免因为内存占用导致的oom问题
>
> 2 阻塞队列可以保证任务队列中没有任务时阻塞获取任务的线程，使得线程进入wait状态，释放cpu资源。当队列中有任务时才唤醒对应线程从队列中取出消息进行执行。

### <u>如何关闭一个线程池</u>

> shutdownnow
>
> shutdown

### <u>如何确定一个线程池的参数 设置是合理的</u>

#### CPU密集型任务

> 尽量使用较小的线程池，一般为CPU核心数+1。 因为CPU密集型任务使得CPU使用率很高，若开过多的线程数，会造成CPU过度切换。

#### IO密集型任务

> 可以使用稍大的线程池，一般为2*CPU核心数。 IO密集型任务CPU使用率并不高，因此可以让CPU在等待IO的时候有其他线程去处理别的任务，充分利用CPU时间。

#### 混合型任务

> 可以将任务分成IO密集型和CPU密集型任务，然后分别用不同的线程池去处理。 只要分完之后两个任务的执行时间相差不大，那么就会比串行执行来的高效。

### <u>Java中的线程池</u>

![](https://upload-images.jianshu.io/upload_images/6024478-9e47d2796c8ab1aa.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

#### newCachedThreadPool

> 用来创建一个可以无限扩大的线程池，适用于负载较轻的场景，执行短期异步任务。（可以使得任务快速得到执行，因为任务时间执行短，可以很快结束，也不会造成cpu过度切换）
>
> **可能会因为创建线程过多导致oom**

#### newFixedThreadPool

> 创建一个固定大小的线程池，因为采用无界的阻塞队列，所以实际线程数量永远不会变化，适用于负载较重的场景，对当前线程数量进行限制。（保证线程数可控，不会造成线程过多，导致系统负载更为严重）
>
> **可能因为等待队列中过长导致oom**

#### newScheduledThreadPool

> 适用于执行延时或者周期性任务。

#### newSingleThreadExecutor

> 创建一个单线程的线程池，适用于需要保证顺序执行各个任务。
>
> **可能因为等待队列中过长导致oom**

### <u>线程池中使用的阻塞工作队列</u>

#### LinkedBlockingQueue

> 三种构造函数
>
> > ​	LinkedBlockingQueue() 无参构造函数，链表长度为Integer.MAX_VALUE
> >
> > ​	LinkedBlockingQueue(int capacity) 指定capacity长度
> >
> > ​	LinkedBlockingQueue(Collection c) 不指定长度，即默认长度为Integer.MAX_VALUE，提供初始化元素
>
> 特点：
>
> > ​	链表节点由Node对象组成，每个Node有item变量用于存储元素，next变量指向下一个节点
> >
> > 执行put的时候，将元素放到链表尾部节点；take的时候从头部取元素
> >
> > 两种操作分别有一个锁putLock, takeLock,互不影响,可以同时进行

#### ArrayBlockingQueue

> 三种构造函数
>
> > ​	ArrayBlockingQueue(int capacity) 指定长度
> >
> > ​	ArrayBlockingQueue(int capacity, boolean fair) 指定长度，及指定是否使用FIFO顺序进出队列
> >
> > ​	ArrayBlockingQueue(int capacity, boolean fair, Collection c) 指定长度，进行队列顺序，初始元素
>
> 特点：
>
> > ​	ArrayBlockingQueue必须指定初始化长度，如果线程池使用该队列，指定长度大了浪费内存，长度小队列并发性不高，在数组满的时候，put操作只能阻塞等待，或者返回false
> >
> > ArrayBlockingQueue 只定义了一个Lock，put和take使用同一锁，不能同时进行

#### SynchronousQueue

> 内部并没有数据缓存空间
>
> 队列头元素是第一个排队要插入数据的**线程**，而不是要交换的数据。数据是在配对的生产者和消费者线程之间直接传递的，并不会将数据缓冲数据到队列中。
>
> 线程池根据需要（新任务到来时）创建新的线程，如果有空闲线程则会重复使用，线程空闲了60秒后会被回收。

![](https://upload-images.jianshu.io/upload_images/16015500-8bf4856f92829bdc.png?imageMogr2/auto-orient/strip|imageView2/2/w/948/format/webp)

### <u>**饱和策略**</u>

> - ThreadPoolExecutor.AbortPolicy：抛出 RejectedExecutionException来拒绝新任务的处理。**抛出异常拒绝**
> - ThreadPoolExecutor.CallerRunsPolicy：调用执行自己的线程运行任务，也就是直接在调用execute方法的线程中运行(run)被拒绝的任务，如果执行程序已关闭，则会丢弃该任务。因此这种策略会降低对于新任务提交速度，影响程序的整体性能。另外，这个策略喜欢增加队列容量。如果您的应用程序可以承受此延迟并且你不能任务丢弃任何一个任务请求的话，你可以选择这个策略。**增加队列容量运行**
> - ThreadPoolExecutor.DiscardPolicy： 不处理新任务，直接丢弃掉。**直接丢弃**
> - ThreadPoolExecutor.DiscardOldestPolicy： 此策略将丢弃最早的未处理的任务请求。**丢弃等待最久的**